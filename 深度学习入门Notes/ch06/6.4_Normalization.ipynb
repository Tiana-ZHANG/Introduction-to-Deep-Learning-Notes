{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.4 正则化\n",
    "解决**过拟合**问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4.1 过拟合 - 6.4.2 权值衰减"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train acc:0.1, test acc:0.1051\n",
      "epoch:1, train acc:0.10333333333333333, test acc:0.1032\n",
      "epoch:2, train acc:0.10666666666666667, test acc:0.106\n",
      "epoch:3, train acc:0.12666666666666668, test acc:0.1139\n",
      "epoch:4, train acc:0.13666666666666666, test acc:0.1241\n",
      "epoch:5, train acc:0.15, test acc:0.1384\n",
      "epoch:6, train acc:0.16666666666666666, test acc:0.1497\n",
      "epoch:7, train acc:0.17, test acc:0.1603\n",
      "epoch:8, train acc:0.18666666666666668, test acc:0.1749\n",
      "epoch:9, train acc:0.21666666666666667, test acc:0.1896\n",
      "epoch:10, train acc:0.23666666666666666, test acc:0.2002\n",
      "epoch:11, train acc:0.26666666666666666, test acc:0.2134\n",
      "epoch:12, train acc:0.2966666666666667, test acc:0.2262\n",
      "epoch:13, train acc:0.32, test acc:0.2401\n",
      "epoch:14, train acc:0.35333333333333333, test acc:0.2601\n",
      "epoch:15, train acc:0.37, test acc:0.2715\n",
      "epoch:16, train acc:0.38333333333333336, test acc:0.2792\n",
      "epoch:17, train acc:0.39, test acc:0.3007\n",
      "epoch:18, train acc:0.4066666666666667, test acc:0.3151\n",
      "epoch:19, train acc:0.43, test acc:0.3238\n",
      "epoch:20, train acc:0.43666666666666665, test acc:0.3298\n",
      "epoch:21, train acc:0.44, test acc:0.341\n",
      "epoch:22, train acc:0.44, test acc:0.3494\n",
      "epoch:23, train acc:0.44666666666666666, test acc:0.3528\n",
      "epoch:24, train acc:0.49, test acc:0.3708\n",
      "epoch:25, train acc:0.5066666666666667, test acc:0.3821\n",
      "epoch:26, train acc:0.5033333333333333, test acc:0.3918\n",
      "epoch:27, train acc:0.5333333333333333, test acc:0.3989\n",
      "epoch:28, train acc:0.52, test acc:0.4017\n",
      "epoch:29, train acc:0.5133333333333333, test acc:0.3989\n",
      "epoch:30, train acc:0.5233333333333333, test acc:0.4057\n",
      "epoch:31, train acc:0.5166666666666667, test acc:0.4078\n",
      "epoch:32, train acc:0.5333333333333333, test acc:0.4203\n",
      "epoch:33, train acc:0.53, test acc:0.4147\n",
      "epoch:34, train acc:0.5433333333333333, test acc:0.4297\n",
      "epoch:35, train acc:0.54, test acc:0.4315\n",
      "epoch:36, train acc:0.58, test acc:0.4416\n",
      "epoch:37, train acc:0.5733333333333334, test acc:0.4419\n",
      "epoch:38, train acc:0.5666666666666667, test acc:0.4373\n",
      "epoch:39, train acc:0.5866666666666667, test acc:0.446\n",
      "epoch:40, train acc:0.5966666666666667, test acc:0.4507\n",
      "epoch:41, train acc:0.6, test acc:0.4551\n",
      "epoch:42, train acc:0.6, test acc:0.4693\n",
      "epoch:43, train acc:0.6, test acc:0.4659\n",
      "epoch:44, train acc:0.6066666666666667, test acc:0.4672\n",
      "epoch:45, train acc:0.6033333333333334, test acc:0.4733\n",
      "epoch:46, train acc:0.6033333333333334, test acc:0.4754\n",
      "epoch:47, train acc:0.5866666666666667, test acc:0.4747\n",
      "epoch:48, train acc:0.6, test acc:0.4802\n",
      "epoch:49, train acc:0.6166666666666667, test acc:0.4846\n",
      "epoch:50, train acc:0.6266666666666667, test acc:0.4892\n",
      "epoch:51, train acc:0.6233333333333333, test acc:0.4981\n",
      "epoch:52, train acc:0.6333333333333333, test acc:0.5072\n",
      "epoch:53, train acc:0.6466666666666666, test acc:0.5169\n",
      "epoch:54, train acc:0.64, test acc:0.5075\n",
      "epoch:55, train acc:0.6233333333333333, test acc:0.5047\n",
      "epoch:56, train acc:0.6433333333333333, test acc:0.5105\n",
      "epoch:57, train acc:0.6733333333333333, test acc:0.5228\n",
      "epoch:58, train acc:0.6833333333333333, test acc:0.5308\n",
      "epoch:59, train acc:0.6866666666666666, test acc:0.5359\n",
      "epoch:60, train acc:0.69, test acc:0.539\n",
      "epoch:61, train acc:0.6733333333333333, test acc:0.5329\n",
      "epoch:62, train acc:0.6666666666666666, test acc:0.5226\n",
      "epoch:63, train acc:0.67, test acc:0.5261\n",
      "epoch:64, train acc:0.6733333333333333, test acc:0.5303\n",
      "epoch:65, train acc:0.6866666666666666, test acc:0.537\n",
      "epoch:66, train acc:0.6733333333333333, test acc:0.5336\n",
      "epoch:67, train acc:0.6833333333333333, test acc:0.5401\n",
      "epoch:68, train acc:0.6833333333333333, test acc:0.5371\n",
      "epoch:69, train acc:0.71, test acc:0.5529\n",
      "epoch:70, train acc:0.6966666666666667, test acc:0.5489\n",
      "epoch:71, train acc:0.69, test acc:0.5442\n",
      "epoch:72, train acc:0.6933333333333334, test acc:0.5501\n",
      "epoch:73, train acc:0.6966666666666667, test acc:0.5579\n",
      "epoch:74, train acc:0.68, test acc:0.5553\n",
      "epoch:75, train acc:0.7, test acc:0.5601\n",
      "epoch:76, train acc:0.7133333333333334, test acc:0.5621\n",
      "epoch:77, train acc:0.73, test acc:0.5627\n",
      "epoch:78, train acc:0.73, test acc:0.571\n",
      "epoch:79, train acc:0.7266666666666667, test acc:0.5719\n",
      "epoch:80, train acc:0.7266666666666667, test acc:0.5775\n",
      "epoch:81, train acc:0.73, test acc:0.5747\n",
      "epoch:82, train acc:0.7266666666666667, test acc:0.5687\n",
      "epoch:83, train acc:0.7266666666666667, test acc:0.5673\n",
      "epoch:84, train acc:0.7233333333333334, test acc:0.5683\n",
      "epoch:85, train acc:0.71, test acc:0.5655\n",
      "epoch:86, train acc:0.7433333333333333, test acc:0.5832\n",
      "epoch:87, train acc:0.74, test acc:0.5892\n",
      "epoch:88, train acc:0.7366666666666667, test acc:0.5841\n",
      "epoch:89, train acc:0.74, test acc:0.5856\n",
      "epoch:90, train acc:0.7433333333333333, test acc:0.5976\n",
      "epoch:91, train acc:0.7266666666666667, test acc:0.5751\n",
      "epoch:92, train acc:0.74, test acc:0.5878\n",
      "epoch:93, train acc:0.73, test acc:0.5919\n",
      "epoch:94, train acc:0.74, test acc:0.5855\n",
      "epoch:95, train acc:0.74, test acc:0.588\n",
      "epoch:96, train acc:0.7366666666666667, test acc:0.5974\n",
      "epoch:97, train acc:0.76, test acc:0.6039\n",
      "epoch:98, train acc:0.76, test acc:0.5994\n",
      "epoch:99, train acc:0.76, test acc:0.6026\n",
      "epoch:100, train acc:0.7533333333333333, test acc:0.5916\n",
      "epoch:101, train acc:0.7466666666666667, test acc:0.5827\n",
      "epoch:102, train acc:0.76, test acc:0.6046\n",
      "epoch:103, train acc:0.79, test acc:0.6319\n",
      "epoch:104, train acc:0.7866666666666666, test acc:0.629\n",
      "epoch:105, train acc:0.7666666666666667, test acc:0.6126\n",
      "epoch:106, train acc:0.7666666666666667, test acc:0.6127\n",
      "epoch:107, train acc:0.7733333333333333, test acc:0.6148\n",
      "epoch:108, train acc:0.7666666666666667, test acc:0.6145\n",
      "epoch:109, train acc:0.79, test acc:0.6249\n",
      "epoch:110, train acc:0.7733333333333333, test acc:0.6177\n",
      "epoch:111, train acc:0.7766666666666666, test acc:0.6255\n",
      "epoch:112, train acc:0.7833333333333333, test acc:0.6167\n",
      "epoch:113, train acc:0.7633333333333333, test acc:0.6004\n",
      "epoch:114, train acc:0.7533333333333333, test acc:0.6028\n",
      "epoch:115, train acc:0.76, test acc:0.6139\n",
      "epoch:116, train acc:0.7666666666666667, test acc:0.6155\n",
      "epoch:117, train acc:0.7866666666666666, test acc:0.6241\n",
      "epoch:118, train acc:0.7933333333333333, test acc:0.6322\n",
      "epoch:119, train acc:0.7966666666666666, test acc:0.6365\n",
      "epoch:120, train acc:0.7866666666666666, test acc:0.6281\n",
      "epoch:121, train acc:0.8066666666666666, test acc:0.6392\n",
      "epoch:122, train acc:0.79, test acc:0.6247\n",
      "epoch:123, train acc:0.8066666666666666, test acc:0.6266\n",
      "epoch:124, train acc:0.8166666666666667, test acc:0.6378\n",
      "epoch:125, train acc:0.8133333333333334, test acc:0.6329\n",
      "epoch:126, train acc:0.8033333333333333, test acc:0.6345\n",
      "epoch:127, train acc:0.8033333333333333, test acc:0.6399\n",
      "epoch:128, train acc:0.81, test acc:0.6378\n",
      "epoch:129, train acc:0.7866666666666666, test acc:0.6224\n",
      "epoch:130, train acc:0.82, test acc:0.6362\n",
      "epoch:131, train acc:0.7933333333333333, test acc:0.634\n",
      "epoch:132, train acc:0.7966666666666666, test acc:0.6278\n",
      "epoch:133, train acc:0.8033333333333333, test acc:0.6352\n",
      "epoch:134, train acc:0.8033333333333333, test acc:0.6277\n",
      "epoch:135, train acc:0.7933333333333333, test acc:0.6301\n",
      "epoch:136, train acc:0.8166666666666667, test acc:0.6494\n",
      "epoch:137, train acc:0.8166666666666667, test acc:0.6401\n",
      "epoch:138, train acc:0.8, test acc:0.6294\n",
      "epoch:139, train acc:0.8033333333333333, test acc:0.6217\n",
      "epoch:140, train acc:0.7766666666666666, test acc:0.6149\n",
      "epoch:141, train acc:0.7866666666666666, test acc:0.6251\n",
      "epoch:142, train acc:0.8033333333333333, test acc:0.6391\n",
      "epoch:143, train acc:0.8166666666666667, test acc:0.6345\n",
      "epoch:144, train acc:0.82, test acc:0.6515\n",
      "epoch:145, train acc:0.81, test acc:0.6359\n",
      "epoch:146, train acc:0.8, test acc:0.6321\n",
      "epoch:147, train acc:0.78, test acc:0.6089\n",
      "epoch:148, train acc:0.82, test acc:0.6449\n",
      "epoch:149, train acc:0.84, test acc:0.6539\n",
      "epoch:150, train acc:0.8266666666666667, test acc:0.6409\n",
      "epoch:151, train acc:0.82, test acc:0.6385\n",
      "epoch:152, train acc:0.82, test acc:0.6464\n",
      "epoch:153, train acc:0.8233333333333334, test acc:0.6395\n",
      "epoch:154, train acc:0.8033333333333333, test acc:0.6306\n",
      "epoch:155, train acc:0.7966666666666666, test acc:0.6382\n",
      "epoch:156, train acc:0.8266666666666667, test acc:0.6458\n",
      "epoch:157, train acc:0.8166666666666667, test acc:0.6492\n",
      "epoch:158, train acc:0.8233333333333334, test acc:0.6468\n",
      "epoch:159, train acc:0.8166666666666667, test acc:0.6595\n",
      "epoch:160, train acc:0.8266666666666667, test acc:0.6591\n",
      "epoch:161, train acc:0.8333333333333334, test acc:0.6607\n",
      "epoch:162, train acc:0.84, test acc:0.6579\n",
      "epoch:163, train acc:0.8366666666666667, test acc:0.6532\n",
      "epoch:164, train acc:0.8233333333333334, test acc:0.6518\n",
      "epoch:165, train acc:0.84, test acc:0.6431\n",
      "epoch:166, train acc:0.8466666666666667, test acc:0.6595\n",
      "epoch:167, train acc:0.8333333333333334, test acc:0.6387\n",
      "epoch:168, train acc:0.84, test acc:0.6579\n",
      "epoch:169, train acc:0.84, test acc:0.6646\n",
      "epoch:170, train acc:0.84, test acc:0.6621\n",
      "epoch:171, train acc:0.8333333333333334, test acc:0.6624\n",
      "epoch:172, train acc:0.8433333333333334, test acc:0.6658\n",
      "epoch:173, train acc:0.85, test acc:0.6633\n",
      "epoch:174, train acc:0.8166666666666667, test acc:0.6442\n",
      "epoch:175, train acc:0.83, test acc:0.6525\n",
      "epoch:176, train acc:0.83, test acc:0.6436\n",
      "epoch:177, train acc:0.8366666666666667, test acc:0.6519\n",
      "epoch:178, train acc:0.8333333333333334, test acc:0.6532\n",
      "epoch:179, train acc:0.84, test acc:0.644\n",
      "epoch:180, train acc:0.8433333333333334, test acc:0.6358\n",
      "epoch:181, train acc:0.8266666666666667, test acc:0.6473\n",
      "epoch:182, train acc:0.8266666666666667, test acc:0.6476\n",
      "epoch:183, train acc:0.7966666666666666, test acc:0.6311\n",
      "epoch:184, train acc:0.8333333333333334, test acc:0.6512\n",
      "epoch:185, train acc:0.8133333333333334, test acc:0.6435\n",
      "epoch:186, train acc:0.8166666666666667, test acc:0.6574\n",
      "epoch:187, train acc:0.83, test acc:0.6542\n",
      "epoch:188, train acc:0.8133333333333334, test acc:0.6414\n",
      "epoch:189, train acc:0.83, test acc:0.6457\n",
      "epoch:190, train acc:0.8233333333333334, test acc:0.6363\n",
      "epoch:191, train acc:0.8366666666666667, test acc:0.6515\n",
      "epoch:192, train acc:0.82, test acc:0.6508\n",
      "epoch:193, train acc:0.83, test acc:0.6555\n",
      "epoch:194, train acc:0.8266666666666667, test acc:0.653\n",
      "epoch:195, train acc:0.8266666666666667, test acc:0.6631\n",
      "epoch:196, train acc:0.84, test acc:0.6656\n",
      "epoch:197, train acc:0.84, test acc:0.6571\n",
      "epoch:198, train acc:0.84, test acc:0.6642\n",
      "epoch:199, train acc:0.8433333333333334, test acc:0.6563\n",
      "epoch:200, train acc:0.82, test acc:0.6442\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ch06/overfit_weight_decay.py\n",
    "# commom/multi_layer_net.py\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.pardir)  # 为了导入父目录的文件而进行的设定\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from common.multi_layer_net import MultiLayerNet\n",
    "from common.optimizer import SGD\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)\n",
    "\n",
    "# 为了再现过拟合，减少学习数据\n",
    "x_train = x_train[:300]\n",
    "t_train = t_train[:300]\n",
    "\n",
    "# weight decay（权值衰减）的设定 =======================\n",
    "#weight_decay_lambda = 0 # 不使用权值衰减的情况\n",
    "weight_decay_lambda = 0.1\n",
    "# ====================================================\n",
    "\n",
    "network = MultiLayerNet(input_size=784, hidden_size_list=[100, 100, 100, 100, 100, 100], output_size=10,\n",
    "                        weight_decay_lambda=weight_decay_lambda)\n",
    "optimizer = SGD(lr=0.01)\n",
    "\n",
    "max_epochs = 201\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "epoch_cnt = 0\n",
    "\n",
    "for i in range(1000000000):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "\n",
    "    grads = network.gradient(x_batch, t_batch)\n",
    "    optimizer.update(network.params, grads)\n",
    "\n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "\n",
    "        print(\"epoch:\" + str(epoch_cnt) + \", train acc:\" + str(train_acc) + \", test acc:\" + str(test_acc))\n",
    "\n",
    "        epoch_cnt += 1\n",
    "        if epoch_cnt >= max_epochs:\n",
    "            break\n",
    "\n",
    "\n",
    "# 3.绘制图形==========\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, train_acc_list, marker='o', label='train', markevery=10)\n",
    "plt.plot(x, test_acc_list, marker='s', label='test', markevery=10)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4.3 Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dropout:\n",
    "\n",
    "    def __init__(self, dropout__ratio=0.5):\n",
    "        self.dropout_ratio = dropout__ratio\n",
    "        self.mask = None\n",
    "\n",
    "    def forward(self, x, train_flg=True):\n",
    "        if train_flg:\n",
    "            self.mask = np.random.rand(*x.shape) > self.dropout_ratio\n",
    "            return x * self.mask\n",
    "        else:\n",
    "            return x * (1.0 - self.dropout_ratio)\n",
    "\n",
    "    def backward(self, dout):\n",
    "        return dout * self.mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST数据集验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.296614939304566\n",
      "=== epoch:1, train acc:0.08333333333333333, test acc:0.1014 ===\n",
      "train loss:2.314665818371766\n",
      "train loss:2.300894876868434\n",
      "train loss:2.2815052318775866\n",
      "=== epoch:2, train acc:0.09, test acc:0.1043 ===\n",
      "train loss:2.2981280356664477\n",
      "train loss:2.296284064422597\n",
      "train loss:2.2932492735710115\n",
      "=== epoch:3, train acc:0.09333333333333334, test acc:0.1073 ===\n",
      "train loss:2.289668896041547\n",
      "train loss:2.3034817801431977\n",
      "train loss:2.297931325688634\n",
      "=== epoch:4, train acc:0.10666666666666667, test acc:0.1107 ===\n",
      "train loss:2.282380393851128\n",
      "train loss:2.279175058283848\n",
      "train loss:2.310572801888299\n",
      "=== epoch:5, train acc:0.10666666666666667, test acc:0.1134 ===\n",
      "train loss:2.2750310396757714\n",
      "train loss:2.298880196781825\n",
      "train loss:2.284005721781578\n",
      "=== epoch:6, train acc:0.10666666666666667, test acc:0.1165 ===\n",
      "train loss:2.279818623503761\n",
      "train loss:2.2994991012075388\n",
      "train loss:2.272919266104081\n",
      "=== epoch:7, train acc:0.10333333333333333, test acc:0.1165 ===\n",
      "train loss:2.302518845708004\n",
      "train loss:2.280841874168085\n",
      "train loss:2.307508185357615\n",
      "=== epoch:8, train acc:0.11, test acc:0.1212 ===\n",
      "train loss:2.293927349850805\n",
      "train loss:2.2831286980486336\n",
      "train loss:2.3037580685457892\n",
      "=== epoch:9, train acc:0.12, test acc:0.1273 ===\n",
      "train loss:2.2836183743532756\n",
      "train loss:2.2914101052215265\n",
      "train loss:2.2900880702257833\n",
      "=== epoch:10, train acc:0.11333333333333333, test acc:0.1295 ===\n",
      "train loss:2.2780011234765096\n",
      "train loss:2.280398156169866\n",
      "train loss:2.2776961479292273\n",
      "=== epoch:11, train acc:0.12666666666666668, test acc:0.1297 ===\n",
      "train loss:2.2830686957836535\n",
      "train loss:2.2946233649838157\n",
      "train loss:2.2854726333390047\n",
      "=== epoch:12, train acc:0.13333333333333333, test acc:0.1322 ===\n",
      "train loss:2.2834185248012404\n",
      "train loss:2.286621119309936\n",
      "train loss:2.289762023555632\n",
      "=== epoch:13, train acc:0.13, test acc:0.1333 ===\n",
      "train loss:2.2815492243909112\n",
      "train loss:2.2689925379691944\n",
      "train loss:2.276178524501341\n",
      "=== epoch:14, train acc:0.14, test acc:0.1364 ===\n",
      "train loss:2.2810019895665317\n",
      "train loss:2.2748576994750835\n",
      "train loss:2.2956891458497806\n",
      "=== epoch:15, train acc:0.15, test acc:0.1404 ===\n",
      "train loss:2.275192892027034\n",
      "train loss:2.2680109420257826\n",
      "train loss:2.275580927846425\n",
      "=== epoch:16, train acc:0.15, test acc:0.1432 ===\n",
      "train loss:2.2709353410188244\n",
      "train loss:2.2882184999909203\n",
      "train loss:2.2618740370346493\n",
      "=== epoch:17, train acc:0.16333333333333333, test acc:0.1514 ===\n",
      "train loss:2.277552439486654\n",
      "train loss:2.262722760766926\n",
      "train loss:2.2813799524039724\n",
      "=== epoch:18, train acc:0.18333333333333332, test acc:0.1536 ===\n",
      "train loss:2.2949326803028267\n",
      "train loss:2.271673388550859\n",
      "train loss:2.2628954047339125\n",
      "=== epoch:19, train acc:0.19, test acc:0.1595 ===\n",
      "train loss:2.2596373166475647\n",
      "train loss:2.287414627001412\n",
      "train loss:2.2894871781557464\n",
      "=== epoch:20, train acc:0.19666666666666666, test acc:0.165 ===\n",
      "train loss:2.286845814000037\n",
      "train loss:2.294145102622969\n",
      "train loss:2.286118998913788\n",
      "=== epoch:21, train acc:0.19333333333333333, test acc:0.1631 ===\n",
      "train loss:2.2702311557594577\n",
      "train loss:2.279740789265958\n",
      "train loss:2.270669700000768\n",
      "=== epoch:22, train acc:0.20333333333333334, test acc:0.17 ===\n",
      "train loss:2.278200490022368\n",
      "train loss:2.273832625459938\n",
      "train loss:2.2597201264486304\n",
      "=== epoch:23, train acc:0.20666666666666667, test acc:0.1769 ===\n",
      "train loss:2.2832470466268338\n",
      "train loss:2.256043931246294\n",
      "train loss:2.280040542980233\n",
      "=== epoch:24, train acc:0.21333333333333335, test acc:0.1789 ===\n",
      "train loss:2.2712136200440445\n",
      "train loss:2.2702259320847444\n",
      "train loss:2.2689626224057666\n",
      "=== epoch:25, train acc:0.21666666666666667, test acc:0.1814 ===\n",
      "train loss:2.2877937907974495\n",
      "train loss:2.297095144679946\n",
      "train loss:2.2687523511724037\n",
      "=== epoch:26, train acc:0.21666666666666667, test acc:0.1848 ===\n",
      "train loss:2.256213535897661\n",
      "train loss:2.270771262906324\n",
      "train loss:2.2686098901882583\n",
      "=== epoch:27, train acc:0.21, test acc:0.1893 ===\n",
      "train loss:2.2825952462981123\n",
      "train loss:2.2717196227912493\n",
      "train loss:2.2809511300290772\n",
      "=== epoch:28, train acc:0.21, test acc:0.1899 ===\n",
      "train loss:2.300489788078224\n",
      "train loss:2.2764792101750024\n",
      "train loss:2.284433346010878\n",
      "=== epoch:29, train acc:0.21333333333333335, test acc:0.1936 ===\n",
      "train loss:2.263808328880018\n",
      "train loss:2.2699085880594074\n",
      "train loss:2.2718675008235096\n",
      "=== epoch:30, train acc:0.22, test acc:0.1917 ===\n",
      "train loss:2.283031172199184\n",
      "train loss:2.273237801604464\n",
      "train loss:2.264173032426289\n",
      "=== epoch:31, train acc:0.22666666666666666, test acc:0.1952 ===\n",
      "train loss:2.2721120349113173\n",
      "train loss:2.2758084199603754\n",
      "train loss:2.2630206844532474\n",
      "=== epoch:32, train acc:0.24666666666666667, test acc:0.1988 ===\n",
      "train loss:2.2650652803110276\n",
      "train loss:2.2662506657832644\n",
      "train loss:2.277862100495794\n",
      "=== epoch:33, train acc:0.24, test acc:0.2023 ===\n",
      "train loss:2.2736762901433907\n",
      "train loss:2.25110712172166\n",
      "train loss:2.2624520738837983\n",
      "=== epoch:34, train acc:0.24333333333333335, test acc:0.2038 ===\n",
      "train loss:2.2601020043084805\n",
      "train loss:2.2491684149822664\n",
      "train loss:2.2564997732632035\n",
      "=== epoch:35, train acc:0.24666666666666667, test acc:0.2095 ===\n",
      "train loss:2.247443820681271\n",
      "train loss:2.2613744503408544\n",
      "train loss:2.264407107450735\n",
      "=== epoch:36, train acc:0.25, test acc:0.2117 ===\n",
      "train loss:2.24705294258094\n",
      "train loss:2.253649638205868\n",
      "train loss:2.274590126743358\n",
      "=== epoch:37, train acc:0.25, test acc:0.2131 ===\n",
      "train loss:2.252617921635088\n",
      "train loss:2.257911365141205\n",
      "train loss:2.256402084442124\n",
      "=== epoch:38, train acc:0.25, test acc:0.2152 ===\n",
      "train loss:2.236377104413094\n",
      "train loss:2.251325050971434\n",
      "train loss:2.24959168820948\n",
      "=== epoch:39, train acc:0.25, test acc:0.2148 ===\n",
      "train loss:2.2456048042609806\n",
      "train loss:2.261000581765149\n",
      "train loss:2.236109701624191\n",
      "=== epoch:40, train acc:0.24333333333333335, test acc:0.2139 ===\n",
      "train loss:2.2739585065439702\n",
      "train loss:2.2441179564209888\n",
      "train loss:2.254231393870361\n",
      "=== epoch:41, train acc:0.25333333333333335, test acc:0.2133 ===\n",
      "train loss:2.2582068733472855\n",
      "train loss:2.2571205092458757\n",
      "train loss:2.2534170504051145\n",
      "=== epoch:42, train acc:0.25, test acc:0.215 ===\n",
      "train loss:2.2513854912629614\n",
      "train loss:2.2520861868284117\n",
      "train loss:2.2413929546679414\n",
      "=== epoch:43, train acc:0.24666666666666667, test acc:0.215 ===\n",
      "train loss:2.2516850405577373\n",
      "train loss:2.2588102565506456\n",
      "train loss:2.2339486582530297\n",
      "=== epoch:44, train acc:0.24333333333333335, test acc:0.2136 ===\n",
      "train loss:2.241401556744653\n",
      "train loss:2.244209299126077\n",
      "train loss:2.258310285243249\n",
      "=== epoch:45, train acc:0.24666666666666667, test acc:0.2139 ===\n",
      "train loss:2.2537770931012098\n",
      "train loss:2.25422732754562\n",
      "train loss:2.2429094767875637\n",
      "=== epoch:46, train acc:0.24333333333333335, test acc:0.2149 ===\n",
      "train loss:2.2636067215139213\n",
      "train loss:2.2615293427619334\n",
      "train loss:2.236191575618138\n",
      "=== epoch:47, train acc:0.24333333333333335, test acc:0.216 ===\n",
      "train loss:2.252705444142787\n",
      "train loss:2.2369970419943805\n",
      "train loss:2.2338065591198024\n",
      "=== epoch:48, train acc:0.24333333333333335, test acc:0.2155 ===\n",
      "train loss:2.2215357701688863\n",
      "train loss:2.2326989640586827\n",
      "train loss:2.238355453191386\n",
      "=== epoch:49, train acc:0.25, test acc:0.2147 ===\n",
      "train loss:2.2368080365875938\n",
      "train loss:2.2357932118767785\n",
      "train loss:2.239019116005906\n",
      "=== epoch:50, train acc:0.25, test acc:0.2157 ===\n",
      "train loss:2.2308030976108046\n",
      "train loss:2.254987861011567\n",
      "train loss:2.222883997218593\n",
      "=== epoch:51, train acc:0.25333333333333335, test acc:0.2156 ===\n",
      "train loss:2.217748162886935\n",
      "train loss:2.2234799936722145\n",
      "train loss:2.2149049469924518\n",
      "=== epoch:52, train acc:0.25, test acc:0.2128 ===\n",
      "train loss:2.2281072983845074\n",
      "train loss:2.2353902349884134\n",
      "train loss:2.252273578592634\n",
      "=== epoch:53, train acc:0.25, test acc:0.2143 ===\n",
      "train loss:2.229189568664306\n",
      "train loss:2.2301932349151925\n",
      "train loss:2.230798394668472\n",
      "=== epoch:54, train acc:0.25, test acc:0.214 ===\n",
      "train loss:2.245223344874214\n",
      "train loss:2.2416237945064723\n",
      "train loss:2.2614902824557115\n",
      "=== epoch:55, train acc:0.25666666666666665, test acc:0.2164 ===\n",
      "train loss:2.228906945197861\n",
      "train loss:2.21141727068307\n",
      "train loss:2.227954363981658\n",
      "=== epoch:56, train acc:0.26, test acc:0.2164 ===\n",
      "train loss:2.2157894206393784\n",
      "train loss:2.229959437318668\n",
      "train loss:2.2228678419631045\n",
      "=== epoch:57, train acc:0.25333333333333335, test acc:0.2153 ===\n",
      "train loss:2.2070923422319937\n",
      "train loss:2.2313057961639244\n",
      "train loss:2.2451918640346475\n",
      "=== epoch:58, train acc:0.25, test acc:0.215 ===\n",
      "train loss:2.224521280885909\n",
      "train loss:2.2239111255617074\n",
      "train loss:2.2336796763481033\n",
      "=== epoch:59, train acc:0.25, test acc:0.2149 ===\n",
      "train loss:2.261881094191605\n",
      "train loss:2.2413136204666957\n",
      "train loss:2.2450303649345362\n",
      "=== epoch:60, train acc:0.25, test acc:0.2161 ===\n",
      "train loss:2.2117661967882616\n",
      "train loss:2.2263174770507503\n",
      "train loss:2.2250994053162874\n",
      "=== epoch:61, train acc:0.24666666666666667, test acc:0.2156 ===\n",
      "train loss:2.207720130132758\n",
      "train loss:2.2224043433042304\n",
      "train loss:2.207336339349023\n",
      "=== epoch:62, train acc:0.24333333333333335, test acc:0.2152 ===\n",
      "train loss:2.2254860120125137\n",
      "train loss:2.2264748054725914\n",
      "train loss:2.2111634837186886\n",
      "=== epoch:63, train acc:0.24333333333333335, test acc:0.2171 ===\n",
      "train loss:2.2182819775637093\n",
      "train loss:2.2284962774918653\n",
      "train loss:2.226651418060361\n",
      "=== epoch:64, train acc:0.25666666666666665, test acc:0.2198 ===\n",
      "train loss:2.2480496071806155\n",
      "train loss:2.200312537448167\n",
      "train loss:2.2024531064050556\n",
      "=== epoch:65, train acc:0.25666666666666665, test acc:0.2197 ===\n",
      "train loss:2.204844431689709\n",
      "train loss:2.230047598222718\n",
      "train loss:2.202135556528897\n",
      "=== epoch:66, train acc:0.26, test acc:0.2205 ===\n",
      "train loss:2.2092239362929966\n",
      "train loss:2.250038962068269\n",
      "train loss:2.2028133797943985\n",
      "=== epoch:67, train acc:0.2633333333333333, test acc:0.22 ===\n",
      "train loss:2.218189488356306\n",
      "train loss:2.1942156858142052\n",
      "train loss:2.2023872305518086\n",
      "=== epoch:68, train acc:0.26, test acc:0.2209 ===\n",
      "train loss:2.226724412876807\n",
      "train loss:2.204852508049264\n",
      "train loss:2.1770041616940357\n",
      "=== epoch:69, train acc:0.26, test acc:0.223 ===\n",
      "train loss:2.2138787127207027\n",
      "train loss:2.211704861116757\n",
      "train loss:2.198433877959321\n",
      "=== epoch:70, train acc:0.2633333333333333, test acc:0.2241 ===\n",
      "train loss:2.196546115813911\n",
      "train loss:2.23404597896511\n",
      "train loss:2.1710212382764564\n",
      "=== epoch:71, train acc:0.26, test acc:0.2241 ===\n",
      "train loss:2.2112053760874733\n",
      "train loss:2.2000035243362412\n",
      "train loss:2.2381217250749232\n",
      "=== epoch:72, train acc:0.26, test acc:0.2244 ===\n",
      "train loss:2.1942238487147696\n",
      "train loss:2.2308275438065777\n",
      "train loss:2.1978216301872915\n",
      "=== epoch:73, train acc:0.26666666666666666, test acc:0.2268 ===\n",
      "train loss:2.194519675782815\n",
      "train loss:2.2119370848703555\n",
      "train loss:2.202728705232258\n",
      "=== epoch:74, train acc:0.26666666666666666, test acc:0.2283 ===\n",
      "train loss:2.216420857985795\n",
      "train loss:2.2226293101002472\n",
      "train loss:2.163103870685942\n",
      "=== epoch:75, train acc:0.2633333333333333, test acc:0.2271 ===\n",
      "train loss:2.1912414307139385\n",
      "train loss:2.1877853917622816\n",
      "train loss:2.2269059772640736\n",
      "=== epoch:76, train acc:0.26, test acc:0.2273 ===\n",
      "train loss:2.2089258099343407\n",
      "train loss:2.210618302501635\n",
      "train loss:2.226721503692133\n",
      "=== epoch:77, train acc:0.26666666666666666, test acc:0.2288 ===\n",
      "train loss:2.2017374412950157\n",
      "train loss:2.2009815885546815\n",
      "train loss:2.1778152365014196\n",
      "=== epoch:78, train acc:0.27, test acc:0.2276 ===\n",
      "train loss:2.1916270259310027\n",
      "train loss:2.2083802825930046\n",
      "train loss:2.222626892922539\n",
      "=== epoch:79, train acc:0.2633333333333333, test acc:0.2283 ===\n",
      "train loss:2.1863739174455215\n",
      "train loss:2.174610756731489\n",
      "train loss:2.201439187085225\n",
      "=== epoch:80, train acc:0.26666666666666666, test acc:0.2299 ===\n",
      "train loss:2.174378601995832\n",
      "train loss:2.1707649989432816\n",
      "train loss:2.1805981576201234\n",
      "=== epoch:81, train acc:0.26, test acc:0.2285 ===\n",
      "train loss:2.144984572724667\n",
      "train loss:2.2103917536673747\n",
      "train loss:2.2052429699759264\n",
      "=== epoch:82, train acc:0.26, test acc:0.228 ===\n",
      "train loss:2.2206408469718046\n",
      "train loss:2.1562122679403823\n",
      "train loss:2.1847023390400993\n",
      "=== epoch:83, train acc:0.25666666666666665, test acc:0.2275 ===\n",
      "train loss:2.136858845613136\n",
      "train loss:2.2103971780620735\n",
      "train loss:2.1477417071949096\n",
      "=== epoch:84, train acc:0.25333333333333335, test acc:0.2261 ===\n",
      "train loss:2.1742268568430023\n",
      "train loss:2.162127987205897\n",
      "train loss:2.231858499898983\n",
      "=== epoch:85, train acc:0.25666666666666665, test acc:0.2259 ===\n",
      "train loss:2.1821673857029626\n",
      "train loss:2.15142879443712\n",
      "train loss:2.1439939211580263\n",
      "=== epoch:86, train acc:0.25, test acc:0.2265 ===\n",
      "train loss:2.1817043762620063\n",
      "train loss:2.178308508589831\n",
      "train loss:2.1750549985039425\n",
      "=== epoch:87, train acc:0.25333333333333335, test acc:0.2257 ===\n",
      "train loss:2.171061415858043\n",
      "train loss:2.182526809024368\n",
      "train loss:2.1895953547578078\n",
      "=== epoch:88, train acc:0.25, test acc:0.2278 ===\n",
      "train loss:2.152376337675286\n",
      "train loss:2.182241624711723\n",
      "train loss:2.189690147351063\n",
      "=== epoch:89, train acc:0.25333333333333335, test acc:0.2292 ===\n",
      "train loss:2.1709156576744335\n",
      "train loss:2.168051841423441\n",
      "train loss:2.1500052858888967\n",
      "=== epoch:90, train acc:0.25333333333333335, test acc:0.2294 ===\n",
      "train loss:2.1311123548848854\n",
      "train loss:2.154241816207863\n",
      "train loss:2.1615873956319738\n",
      "=== epoch:91, train acc:0.25333333333333335, test acc:0.2304 ===\n",
      "train loss:2.172459899870547\n",
      "train loss:2.1689861276449065\n",
      "train loss:2.166596452322929\n",
      "=== epoch:92, train acc:0.26, test acc:0.2289 ===\n",
      "train loss:2.176606679303893\n",
      "train loss:2.208761067983907\n",
      "train loss:2.1193476908715496\n",
      "=== epoch:93, train acc:0.25666666666666665, test acc:0.2302 ===\n",
      "train loss:2.188633233686724\n",
      "train loss:2.1562066115556973\n",
      "train loss:2.1304674316542305\n",
      "=== epoch:94, train acc:0.25333333333333335, test acc:0.2292 ===\n",
      "train loss:2.212008716017792\n",
      "train loss:2.113500166528374\n",
      "train loss:2.1513919671304325\n",
      "=== epoch:95, train acc:0.25333333333333335, test acc:0.2295 ===\n",
      "train loss:2.1582892098082347\n",
      "train loss:2.139655653657864\n",
      "train loss:2.1490242330783733\n",
      "=== epoch:96, train acc:0.25666666666666665, test acc:0.2291 ===\n",
      "train loss:2.206857098014467\n",
      "train loss:2.149253545051385\n",
      "train loss:2.1625562261683133\n",
      "=== epoch:97, train acc:0.26, test acc:0.2304 ===\n",
      "train loss:2.117428108474549\n",
      "train loss:2.092402367530976\n",
      "train loss:2.1452425345097548\n",
      "=== epoch:98, train acc:0.25666666666666665, test acc:0.23 ===\n",
      "train loss:2.1731542723660975\n",
      "train loss:2.1209612673937976\n",
      "train loss:2.1310414361776377\n",
      "=== epoch:99, train acc:0.25666666666666665, test acc:0.2306 ===\n",
      "train loss:2.1502556049490362\n",
      "train loss:2.091264321312254\n",
      "train loss:2.122162058672716\n",
      "=== epoch:100, train acc:0.26, test acc:0.2297 ===\n",
      "train loss:2.1652676872252936\n",
      "train loss:2.17403630598386\n",
      "train loss:2.116668522330512\n",
      "=== epoch:101, train acc:0.2633333333333333, test acc:0.231 ===\n",
      "train loss:2.1607529772509877\n",
      "train loss:2.150029024750662\n",
      "train loss:2.135997481580041\n",
      "=== epoch:102, train acc:0.27, test acc:0.2321 ===\n",
      "train loss:2.128576878617897\n",
      "train loss:2.1484921319132453\n",
      "train loss:2.131122623741847\n",
      "=== epoch:103, train acc:0.27, test acc:0.2327 ===\n",
      "train loss:2.0998266277120847\n",
      "train loss:2.142993854263704\n",
      "train loss:2.104772423649155\n",
      "=== epoch:104, train acc:0.27, test acc:0.2333 ===\n",
      "train loss:2.121046218667843\n",
      "train loss:2.141474693166517\n",
      "train loss:2.156282617533251\n",
      "=== epoch:105, train acc:0.27666666666666667, test acc:0.2344 ===\n",
      "train loss:2.1563321322082776\n",
      "train loss:2.1124065401492818\n",
      "train loss:2.139633191342321\n",
      "=== epoch:106, train acc:0.2833333333333333, test acc:0.235 ===\n",
      "train loss:2.145359060844688\n",
      "train loss:2.130709756912044\n",
      "train loss:2.100229480551791\n",
      "=== epoch:107, train acc:0.2833333333333333, test acc:0.2356 ===\n",
      "train loss:2.1375567221598466\n",
      "train loss:2.0675185556770423\n",
      "train loss:2.093548510395032\n",
      "=== epoch:108, train acc:0.2866666666666667, test acc:0.2357 ===\n",
      "train loss:2.152283477641374\n",
      "train loss:2.145191164147927\n",
      "train loss:2.1095189497764135\n",
      "=== epoch:109, train acc:0.2866666666666667, test acc:0.2386 ===\n",
      "train loss:2.104230144753191\n",
      "train loss:2.120767041885381\n",
      "train loss:2.1091078968533146\n",
      "=== epoch:110, train acc:0.2866666666666667, test acc:0.2383 ===\n",
      "train loss:2.0950455663934395\n",
      "train loss:2.0377213139220025\n",
      "train loss:2.1085762308210967\n",
      "=== epoch:111, train acc:0.2866666666666667, test acc:0.2367 ===\n",
      "train loss:2.1641804014960644\n",
      "train loss:2.0655523380043928\n",
      "train loss:2.0676527518457046\n",
      "=== epoch:112, train acc:0.2866666666666667, test acc:0.2362 ===\n",
      "train loss:2.1204867344260556\n",
      "train loss:2.1286077253510722\n",
      "train loss:2.0946025483075053\n",
      "=== epoch:113, train acc:0.2833333333333333, test acc:0.2382 ===\n",
      "train loss:2.1258182523821714\n",
      "train loss:2.119768731935948\n",
      "train loss:2.126219403159399\n",
      "=== epoch:114, train acc:0.2866666666666667, test acc:0.2402 ===\n",
      "train loss:2.0915241384092065\n",
      "train loss:2.0861070649385804\n",
      "train loss:2.09345724681984\n",
      "=== epoch:115, train acc:0.2866666666666667, test acc:0.2405 ===\n",
      "train loss:2.146459411907859\n",
      "train loss:2.123427894193741\n",
      "train loss:2.12217780930323\n",
      "=== epoch:116, train acc:0.29, test acc:0.2414 ===\n",
      "train loss:2.088033491826589\n",
      "train loss:2.1513378014169713\n",
      "train loss:2.069910975413094\n",
      "=== epoch:117, train acc:0.2966666666666667, test acc:0.2416 ===\n",
      "train loss:2.0977610092864616\n",
      "train loss:2.1083773147010403\n",
      "train loss:2.0145196885769217\n",
      "=== epoch:118, train acc:0.29, test acc:0.2418 ===\n",
      "train loss:2.0668160058149927\n",
      "train loss:2.084182717729129\n",
      "train loss:2.060525340556731\n",
      "=== epoch:119, train acc:0.29, test acc:0.2408 ===\n",
      "train loss:2.0383638744079664\n",
      "train loss:2.069378102799542\n",
      "train loss:2.029023534833191\n",
      "=== epoch:120, train acc:0.29333333333333333, test acc:0.2385 ===\n",
      "train loss:2.059610418508128\n",
      "train loss:2.053318478323885\n",
      "train loss:2.1122422250997586\n",
      "=== epoch:121, train acc:0.2866666666666667, test acc:0.2383 ===\n",
      "train loss:2.0704549561286725\n",
      "train loss:2.0445507678981345\n",
      "train loss:1.9748361348959869\n",
      "=== epoch:122, train acc:0.29333333333333333, test acc:0.2379 ===\n",
      "train loss:2.028246121066602\n",
      "train loss:2.0250907840781216\n",
      "train loss:2.005118617479021\n",
      "=== epoch:123, train acc:0.2866666666666667, test acc:0.2367 ===\n",
      "train loss:2.0977204148787196\n",
      "train loss:2.083737282788129\n",
      "train loss:2.03465406689806\n",
      "=== epoch:124, train acc:0.2966666666666667, test acc:0.2389 ===\n",
      "train loss:1.941302829087258\n",
      "train loss:2.108145504769593\n",
      "train loss:2.105339582795824\n",
      "=== epoch:125, train acc:0.29333333333333333, test acc:0.2445 ===\n",
      "train loss:1.9995720659912377\n",
      "train loss:2.0597973182119023\n",
      "train loss:2.0363425262338835\n",
      "=== epoch:126, train acc:0.29, test acc:0.2452 ===\n",
      "train loss:2.0818154917920593\n",
      "train loss:2.118349438169261\n",
      "train loss:2.045472869690373\n",
      "=== epoch:127, train acc:0.2966666666666667, test acc:0.2487 ===\n",
      "train loss:2.0013474221849914\n",
      "train loss:1.9776790913648774\n",
      "train loss:2.0395330057390444\n",
      "=== epoch:128, train acc:0.3, test acc:0.2478 ===\n",
      "train loss:2.0752826044752735\n",
      "train loss:2.046056925538049\n",
      "train loss:2.023103474089253\n",
      "=== epoch:129, train acc:0.3, test acc:0.2497 ===\n",
      "train loss:2.041141570369369\n",
      "train loss:1.9469651297117943\n",
      "train loss:2.049352992398796\n",
      "=== epoch:130, train acc:0.3, test acc:0.253 ===\n",
      "train loss:1.9561557360526585\n",
      "train loss:2.0385675244633426\n",
      "train loss:2.0257553754433193\n",
      "=== epoch:131, train acc:0.30333333333333334, test acc:0.2517 ===\n",
      "train loss:2.055366070186077\n",
      "train loss:2.0181904592729323\n",
      "train loss:2.02201353000477\n",
      "=== epoch:132, train acc:0.30333333333333334, test acc:0.2547 ===\n",
      "train loss:2.0653366797725665\n",
      "train loss:2.0744324787933506\n",
      "train loss:1.9788827106042106\n",
      "=== epoch:133, train acc:0.30333333333333334, test acc:0.2569 ===\n",
      "train loss:2.005111532983359\n",
      "train loss:2.0056164590691186\n",
      "train loss:1.9303594985497718\n",
      "=== epoch:134, train acc:0.30333333333333334, test acc:0.2588 ===\n",
      "train loss:2.038933830748445\n",
      "train loss:2.0104709654724795\n",
      "train loss:1.9478094258262235\n",
      "=== epoch:135, train acc:0.30666666666666664, test acc:0.2586 ===\n",
      "train loss:1.9771846280370684\n",
      "train loss:2.075902114126807\n",
      "train loss:2.041315588991013\n",
      "=== epoch:136, train acc:0.31, test acc:0.2628 ===\n",
      "train loss:2.033591267524356\n",
      "train loss:1.9898465445592495\n",
      "train loss:1.9829193261671005\n",
      "=== epoch:137, train acc:0.30666666666666664, test acc:0.2654 ===\n",
      "train loss:2.040577582350236\n",
      "train loss:1.9345314617390037\n",
      "train loss:1.9852440002127159\n",
      "=== epoch:138, train acc:0.31666666666666665, test acc:0.2664 ===\n",
      "train loss:1.9751165650947113\n",
      "train loss:1.9377042464639935\n",
      "train loss:1.9817227826191381\n",
      "=== epoch:139, train acc:0.30666666666666664, test acc:0.2633 ===\n",
      "train loss:2.0016878382401715\n",
      "train loss:1.9327434111231963\n",
      "train loss:2.0012884921088765\n",
      "=== epoch:140, train acc:0.31333333333333335, test acc:0.2656 ===\n",
      "train loss:2.030155839291768\n",
      "train loss:2.0112071062791603\n",
      "train loss:1.9889390976753958\n",
      "=== epoch:141, train acc:0.3233333333333333, test acc:0.2721 ===\n",
      "train loss:2.042407740485545\n",
      "train loss:1.9676823813307047\n",
      "train loss:2.071119233111931\n",
      "=== epoch:142, train acc:0.3333333333333333, test acc:0.2778 ===\n",
      "train loss:1.9386786650407286\n",
      "train loss:1.8897240115186835\n",
      "train loss:2.037577959473845\n",
      "=== epoch:143, train acc:0.34, test acc:0.2778 ===\n",
      "train loss:1.978534180259017\n",
      "train loss:1.9896493607206513\n",
      "train loss:1.9462353578146447\n",
      "=== epoch:144, train acc:0.33666666666666667, test acc:0.2789 ===\n",
      "train loss:2.005852028575686\n",
      "train loss:2.0316417413614265\n",
      "train loss:1.9424450886012543\n",
      "=== epoch:145, train acc:0.3333333333333333, test acc:0.2798 ===\n",
      "train loss:2.0131668057385217\n",
      "train loss:1.9282968165163084\n",
      "train loss:1.9132529290619829\n",
      "=== epoch:146, train acc:0.3333333333333333, test acc:0.2802 ===\n",
      "train loss:1.9710886162712893\n",
      "train loss:1.9268198651742454\n",
      "train loss:2.0121495614625364\n",
      "=== epoch:147, train acc:0.34, test acc:0.2848 ===\n",
      "train loss:1.9681070056558974\n",
      "train loss:1.9371097252726017\n",
      "train loss:1.8713591707735324\n",
      "=== epoch:148, train acc:0.3333333333333333, test acc:0.2855 ===\n",
      "train loss:1.961213609362255\n",
      "train loss:1.9309212496785104\n",
      "train loss:1.920742548254651\n",
      "=== epoch:149, train acc:0.34, test acc:0.2878 ===\n",
      "train loss:2.0085162785011037\n",
      "train loss:1.9446464549345945\n",
      "train loss:1.9585840610750367\n",
      "=== epoch:150, train acc:0.33666666666666667, test acc:0.2911 ===\n",
      "train loss:1.9546524127801914\n",
      "train loss:1.9484431381844873\n",
      "train loss:1.9330817802165094\n",
      "=== epoch:151, train acc:0.34, test acc:0.2916 ===\n",
      "train loss:1.9996631999595291\n",
      "train loss:2.0220656569697373\n",
      "train loss:1.9483306971415388\n",
      "=== epoch:152, train acc:0.36, test acc:0.2948 ===\n",
      "train loss:2.0003050386278547\n",
      "train loss:1.9598228183594473\n",
      "train loss:1.914340649342284\n",
      "=== epoch:153, train acc:0.35333333333333333, test acc:0.2974 ===\n",
      "train loss:1.9622828250793412\n",
      "train loss:1.8667924156979043\n",
      "train loss:1.9339014731995454\n",
      "=== epoch:154, train acc:0.36, test acc:0.2989 ===\n",
      "train loss:1.8818342872015583\n",
      "train loss:1.9142437927415863\n",
      "train loss:1.8207508279310207\n",
      "=== epoch:155, train acc:0.36333333333333334, test acc:0.2994 ===\n",
      "train loss:1.8812865168195598\n",
      "train loss:1.962510609610581\n",
      "train loss:1.9371628160796286\n",
      "=== epoch:156, train acc:0.35, test acc:0.3 ===\n",
      "train loss:1.9020033835094516\n",
      "train loss:1.9302631749837948\n",
      "train loss:1.9503056670032604\n",
      "=== epoch:157, train acc:0.37, test acc:0.3068 ===\n",
      "train loss:1.9135689097170856\n",
      "train loss:1.94679326327348\n",
      "train loss:1.911753200168387\n",
      "=== epoch:158, train acc:0.36666666666666664, test acc:0.3101 ===\n",
      "train loss:1.9767452805461514\n",
      "train loss:1.9237637088714457\n",
      "train loss:1.8667605793421251\n",
      "=== epoch:159, train acc:0.38, test acc:0.3137 ===\n",
      "train loss:1.8590999716293992\n",
      "train loss:1.916779766134727\n",
      "train loss:1.9370908557880515\n",
      "=== epoch:160, train acc:0.39, test acc:0.3181 ===\n",
      "train loss:1.9925816569427246\n",
      "train loss:1.8405795342624338\n",
      "train loss:1.8333154005281154\n",
      "=== epoch:161, train acc:0.38666666666666666, test acc:0.3191 ===\n",
      "train loss:1.846401787935585\n",
      "train loss:1.8736244514789175\n",
      "train loss:1.8947907302358977\n",
      "=== epoch:162, train acc:0.39, test acc:0.3194 ===\n",
      "train loss:1.8400197288274762\n",
      "train loss:1.970907995917544\n",
      "train loss:1.90562134653614\n",
      "=== epoch:163, train acc:0.3933333333333333, test acc:0.3201 ===\n",
      "train loss:1.8444884610417696\n",
      "train loss:1.8440228797363505\n",
      "train loss:1.722356796594651\n",
      "=== epoch:164, train acc:0.38, test acc:0.3188 ===\n",
      "train loss:1.7982702103064334\n",
      "train loss:1.891456097151467\n",
      "train loss:1.8337651079405726\n",
      "=== epoch:165, train acc:0.39, test acc:0.3223 ===\n",
      "train loss:1.9104682202566974\n",
      "train loss:1.9147605481824739\n",
      "train loss:1.8964676238965053\n",
      "=== epoch:166, train acc:0.3933333333333333, test acc:0.3229 ===\n",
      "train loss:1.8839624418852623\n",
      "train loss:1.8502943326007135\n",
      "train loss:1.8633109839176776\n",
      "=== epoch:167, train acc:0.4033333333333333, test acc:0.3284 ===\n",
      "train loss:1.8365968925315355\n",
      "train loss:1.8049588369759832\n",
      "train loss:1.8023752169523721\n",
      "=== epoch:168, train acc:0.4066666666666667, test acc:0.3289 ===\n",
      "train loss:1.734595911110044\n",
      "train loss:1.7648120846992774\n",
      "train loss:1.8571360859543165\n",
      "=== epoch:169, train acc:0.4066666666666667, test acc:0.3274 ===\n",
      "train loss:1.875600384573428\n",
      "train loss:1.8375178722451966\n",
      "train loss:1.8895536437147538\n",
      "=== epoch:170, train acc:0.41, test acc:0.3297 ===\n",
      "train loss:1.8049104412922177\n",
      "train loss:1.8667186676468301\n",
      "train loss:1.804748048380146\n",
      "=== epoch:171, train acc:0.41, test acc:0.3351 ===\n",
      "train loss:1.853856247849521\n",
      "train loss:1.8587829382570422\n",
      "train loss:1.8185158742104781\n",
      "=== epoch:172, train acc:0.4166666666666667, test acc:0.3358 ===\n",
      "train loss:1.8014261545675045\n",
      "train loss:1.8523296311570527\n",
      "train loss:1.9279756231706866\n",
      "=== epoch:173, train acc:0.42333333333333334, test acc:0.3409 ===\n",
      "train loss:1.7949118036213714\n",
      "train loss:1.7462403717522748\n",
      "train loss:1.784304015706106\n",
      "=== epoch:174, train acc:0.42333333333333334, test acc:0.3381 ===\n",
      "train loss:1.8189592529331768\n",
      "train loss:1.8156737535388388\n",
      "train loss:1.8412136492516722\n",
      "=== epoch:175, train acc:0.42333333333333334, test acc:0.3389 ===\n",
      "train loss:1.8233175414412504\n",
      "train loss:1.823713226164971\n",
      "train loss:1.8460653593077552\n",
      "=== epoch:176, train acc:0.44, test acc:0.3446 ===\n",
      "train loss:1.8245367165853619\n",
      "train loss:1.7901518614341043\n",
      "train loss:1.7117142051761467\n",
      "=== epoch:177, train acc:0.44666666666666666, test acc:0.3469 ===\n",
      "train loss:1.7720459368819277\n",
      "train loss:1.720798278794545\n",
      "train loss:1.6919636960282685\n",
      "=== epoch:178, train acc:0.43666666666666665, test acc:0.3473 ===\n",
      "train loss:1.7295937880932766\n",
      "train loss:1.7989717148778162\n",
      "train loss:1.7645815478537281\n",
      "=== epoch:179, train acc:0.43666666666666665, test acc:0.3497 ===\n",
      "train loss:1.8351654948333915\n",
      "train loss:1.7658335820842987\n",
      "train loss:1.7267762621093814\n",
      "=== epoch:180, train acc:0.44, test acc:0.3521 ===\n",
      "train loss:1.7629935012609832\n",
      "train loss:1.7609829710848157\n",
      "train loss:1.7955273120475468\n",
      "=== epoch:181, train acc:0.44, test acc:0.3528 ===\n",
      "train loss:1.807932513862529\n",
      "train loss:1.7090058261077998\n",
      "train loss:1.860886070546474\n",
      "=== epoch:182, train acc:0.45, test acc:0.3577 ===\n",
      "train loss:1.7398463884893607\n",
      "train loss:1.819911203246305\n",
      "train loss:1.8388378359756794\n",
      "=== epoch:183, train acc:0.45666666666666667, test acc:0.3584 ===\n",
      "train loss:1.724621492294563\n",
      "train loss:1.7120681260800228\n",
      "train loss:1.8405402482208613\n",
      "=== epoch:184, train acc:0.4533333333333333, test acc:0.3607 ===\n",
      "train loss:1.6653409954915217\n",
      "train loss:1.8055945971163616\n",
      "train loss:1.7595685662977198\n",
      "=== epoch:185, train acc:0.4533333333333333, test acc:0.3604 ===\n",
      "train loss:1.776123261136078\n",
      "train loss:1.7650702791997015\n",
      "train loss:1.7964732615689858\n",
      "=== epoch:186, train acc:0.46, test acc:0.3632 ===\n",
      "train loss:1.8870197443077674\n",
      "train loss:1.848350163461903\n",
      "train loss:1.7805724618445793\n",
      "=== epoch:187, train acc:0.4666666666666667, test acc:0.371 ===\n",
      "train loss:1.8267798792878756\n",
      "train loss:1.7023531808944008\n",
      "train loss:1.7262782613281675\n",
      "=== epoch:188, train acc:0.47, test acc:0.3698 ===\n",
      "train loss:1.7082364474182117\n",
      "train loss:1.74553532626673\n",
      "train loss:1.6970377874343965\n",
      "=== epoch:189, train acc:0.47, test acc:0.3698 ===\n",
      "train loss:1.7131647701651562\n",
      "train loss:1.6613443731839077\n",
      "train loss:1.6771393919506827\n",
      "=== epoch:190, train acc:0.47, test acc:0.3708 ===\n",
      "train loss:1.730679859034372\n",
      "train loss:1.6518727532679915\n",
      "train loss:1.823086729624732\n",
      "=== epoch:191, train acc:0.4766666666666667, test acc:0.3728 ===\n",
      "train loss:1.6701299379111012\n",
      "train loss:1.8385863610388953\n",
      "train loss:1.6692525796941067\n",
      "=== epoch:192, train acc:0.49, test acc:0.3751 ===\n",
      "train loss:1.7486662939995756\n",
      "train loss:1.815244064155665\n",
      "train loss:1.8166903020945788\n",
      "=== epoch:193, train acc:0.49666666666666665, test acc:0.3834 ===\n",
      "train loss:1.6725315496647455\n",
      "train loss:1.6854732340825607\n",
      "train loss:1.5726348153875849\n",
      "=== epoch:194, train acc:0.4866666666666667, test acc:0.3775 ===\n",
      "train loss:1.635347350048025\n",
      "train loss:1.7006204401797687\n",
      "train loss:1.784150970543806\n",
      "=== epoch:195, train acc:0.48333333333333334, test acc:0.3774 ===\n",
      "train loss:1.7546400728010223\n",
      "train loss:1.7737738366996332\n",
      "train loss:1.8134379473187985\n",
      "=== epoch:196, train acc:0.49333333333333335, test acc:0.3804 ===\n",
      "train loss:1.7546425130090861\n",
      "train loss:1.7469215124004953\n",
      "train loss:1.7022272486490575\n",
      "=== epoch:197, train acc:0.49, test acc:0.3813 ===\n",
      "train loss:1.7818051874079905\n",
      "train loss:1.7415846663123227\n",
      "train loss:1.6416208397668293\n",
      "=== epoch:198, train acc:0.49666666666666665, test acc:0.3875 ===\n",
      "train loss:1.786469779355318\n",
      "train loss:1.7301208300296467\n",
      "train loss:1.6496080554561887\n",
      "=== epoch:199, train acc:0.5066666666666667, test acc:0.3917 ===\n",
      "train loss:1.7379734486875804\n",
      "train loss:1.581737852626872\n",
      "train loss:1.7224942166550254\n",
      "=== epoch:200, train acc:0.51, test acc:0.3928 ===\n",
      "train loss:1.665274749969238\n",
      "train loss:1.7028656987986768\n",
      "train loss:1.7190207587872846\n",
      "=== epoch:201, train acc:0.5033333333333333, test acc:0.3966 ===\n",
      "train loss:1.6037436464279278\n",
      "train loss:1.8139090456105236\n",
      "train loss:1.6467348181162438\n",
      "=== epoch:202, train acc:0.51, test acc:0.3999 ===\n",
      "train loss:1.6881955850299724\n",
      "train loss:1.6857830421928994\n",
      "train loss:1.6225254981391353\n",
      "=== epoch:203, train acc:0.5233333333333333, test acc:0.4052 ===\n",
      "train loss:1.6787959380202275\n",
      "train loss:1.557417113412681\n",
      "train loss:1.7016501245726143\n",
      "=== epoch:204, train acc:0.5266666666666666, test acc:0.4082 ===\n",
      "train loss:1.6271302080745673\n",
      "train loss:1.6724024267299635\n",
      "train loss:1.682665816436401\n",
      "=== epoch:205, train acc:0.5266666666666666, test acc:0.4108 ===\n",
      "train loss:1.709418331141208\n",
      "train loss:1.7145100115039336\n",
      "train loss:1.6340436862588792\n",
      "=== epoch:206, train acc:0.5266666666666666, test acc:0.4123 ===\n",
      "train loss:1.5964623421691866\n",
      "train loss:1.6026752387808207\n",
      "train loss:1.6528736430092252\n",
      "=== epoch:207, train acc:0.52, test acc:0.4118 ===\n",
      "train loss:1.6428977093490351\n",
      "train loss:1.4719658052451359\n",
      "train loss:1.5655841657352514\n",
      "=== epoch:208, train acc:0.5233333333333333, test acc:0.4096 ===\n",
      "train loss:1.6303245101047132\n",
      "train loss:1.4370733976115906\n",
      "train loss:1.6192322171051916\n",
      "=== epoch:209, train acc:0.5266666666666666, test acc:0.4099 ===\n",
      "train loss:1.6030324116222892\n",
      "train loss:1.6635931374911948\n",
      "train loss:1.5200424850377836\n",
      "=== epoch:210, train acc:0.5466666666666666, test acc:0.415 ===\n",
      "train loss:1.6792395395236435\n",
      "train loss:1.5701409386067118\n",
      "train loss:1.64717405542015\n",
      "=== epoch:211, train acc:0.55, test acc:0.4183 ===\n",
      "train loss:1.767783760598538\n",
      "train loss:1.5241262475606334\n",
      "train loss:1.592994599079611\n",
      "=== epoch:212, train acc:0.55, test acc:0.4185 ===\n",
      "train loss:1.6904001543340286\n",
      "train loss:1.5884565773807597\n",
      "train loss:1.7309138219350175\n",
      "=== epoch:213, train acc:0.5566666666666666, test acc:0.4232 ===\n",
      "train loss:1.6144320611999876\n",
      "train loss:1.593301967832505\n",
      "train loss:1.7207301513789792\n",
      "=== epoch:214, train acc:0.56, test acc:0.4236 ===\n",
      "train loss:1.4090707533159619\n",
      "train loss:1.5857072519912037\n",
      "train loss:1.6095929145879933\n",
      "=== epoch:215, train acc:0.5533333333333333, test acc:0.4234 ===\n",
      "train loss:1.6591501480347666\n",
      "train loss:1.5826587123630496\n",
      "train loss:1.487958077708221\n",
      "=== epoch:216, train acc:0.5633333333333334, test acc:0.4259 ===\n",
      "train loss:1.360207647086425\n",
      "train loss:1.7016475102463808\n",
      "train loss:1.5908019730484353\n",
      "=== epoch:217, train acc:0.5633333333333334, test acc:0.4232 ===\n",
      "train loss:1.581760135188447\n",
      "train loss:1.4031148875748989\n",
      "train loss:1.6847838984932286\n",
      "=== epoch:218, train acc:0.5533333333333333, test acc:0.4235 ===\n",
      "train loss:1.5957883664077617\n",
      "train loss:1.6418362336792556\n",
      "train loss:1.5389352529995113\n",
      "=== epoch:219, train acc:0.56, test acc:0.4286 ===\n",
      "train loss:1.5910193764892668\n",
      "train loss:1.5755858634937063\n",
      "train loss:1.4843561915873367\n",
      "=== epoch:220, train acc:0.56, test acc:0.4315 ===\n",
      "train loss:1.635276437965322\n",
      "train loss:1.495606866865276\n",
      "train loss:1.505581469084139\n",
      "=== epoch:221, train acc:0.57, test acc:0.4353 ===\n",
      "train loss:1.571982915681543\n",
      "train loss:1.5822722857638067\n",
      "train loss:1.357483318755677\n",
      "=== epoch:222, train acc:0.5633333333333334, test acc:0.4356 ===\n",
      "train loss:1.5050439744112654\n",
      "train loss:1.6095743015553952\n",
      "train loss:1.5909341880746157\n",
      "=== epoch:223, train acc:0.5666666666666667, test acc:0.4346 ===\n",
      "train loss:1.498448418834427\n",
      "train loss:1.4346773273158047\n",
      "train loss:1.4909976991007305\n",
      "=== epoch:224, train acc:0.5666666666666667, test acc:0.4336 ===\n",
      "train loss:1.5655925189577704\n",
      "train loss:1.5086084658370948\n",
      "train loss:1.4573220765082826\n",
      "=== epoch:225, train acc:0.57, test acc:0.4382 ===\n",
      "train loss:1.4701496131798937\n",
      "train loss:1.5699661417112452\n",
      "train loss:1.6868430704917208\n",
      "=== epoch:226, train acc:0.5766666666666667, test acc:0.4417 ===\n",
      "train loss:1.5443217880193842\n",
      "train loss:1.6793545701545063\n",
      "train loss:1.4231894230445903\n",
      "=== epoch:227, train acc:0.58, test acc:0.4471 ===\n",
      "train loss:1.6292155197469058\n",
      "train loss:1.6064139241897797\n",
      "train loss:1.7194629911199748\n",
      "=== epoch:228, train acc:0.59, test acc:0.4555 ===\n",
      "train loss:1.6363145142342825\n",
      "train loss:1.561359872283849\n",
      "train loss:1.4999377927671516\n",
      "=== epoch:229, train acc:0.59, test acc:0.4616 ===\n",
      "train loss:1.532442791962683\n",
      "train loss:1.5746043545511506\n",
      "train loss:1.5307930635964437\n",
      "=== epoch:230, train acc:0.59, test acc:0.4595 ===\n",
      "train loss:1.4753807238792729\n",
      "train loss:1.4757169569615007\n",
      "train loss:1.7048184197532001\n",
      "=== epoch:231, train acc:0.59, test acc:0.4634 ===\n",
      "train loss:1.648355156990281\n",
      "train loss:1.6086340372573948\n",
      "train loss:1.4797248006458787\n",
      "=== epoch:232, train acc:0.5933333333333334, test acc:0.4608 ===\n",
      "train loss:1.4277338639268644\n",
      "train loss:1.5276741279057804\n",
      "train loss:1.5978046354164679\n",
      "=== epoch:233, train acc:0.5933333333333334, test acc:0.4627 ===\n",
      "train loss:1.5500799749336494\n",
      "train loss:1.4660175191412435\n",
      "train loss:1.5798891231210126\n",
      "=== epoch:234, train acc:0.5933333333333334, test acc:0.467 ===\n",
      "train loss:1.5159355935895118\n",
      "train loss:1.4694575989074017\n",
      "train loss:1.506801753861848\n",
      "=== epoch:235, train acc:0.59, test acc:0.4676 ===\n",
      "train loss:1.6204769522276168\n",
      "train loss:1.5228469766306358\n",
      "train loss:1.4517115301236296\n",
      "=== epoch:236, train acc:0.5933333333333334, test acc:0.4702 ===\n",
      "train loss:1.527665269120536\n",
      "train loss:1.5997456967124553\n",
      "train loss:1.520231763818732\n",
      "=== epoch:237, train acc:0.6, test acc:0.4745 ===\n",
      "train loss:1.512949966165559\n",
      "train loss:1.5095570290973481\n",
      "train loss:1.623632156398364\n",
      "=== epoch:238, train acc:0.6, test acc:0.4742 ===\n",
      "train loss:1.4197802697538107\n",
      "train loss:1.4465629712742496\n",
      "train loss:1.3866543136701133\n",
      "=== epoch:239, train acc:0.5966666666666667, test acc:0.476 ===\n",
      "train loss:1.4323802879966894\n",
      "train loss:1.4651385102361651\n",
      "train loss:1.4717760324312794\n",
      "=== epoch:240, train acc:0.5966666666666667, test acc:0.4711 ===\n",
      "train loss:1.4379163114365918\n",
      "train loss:1.399633355743052\n",
      "train loss:1.4998189834710807\n",
      "=== epoch:241, train acc:0.6, test acc:0.4737 ===\n",
      "train loss:1.3701853865742197\n",
      "train loss:1.4430067357625413\n",
      "train loss:1.3892903650910917\n",
      "=== epoch:242, train acc:0.6033333333333334, test acc:0.4752 ===\n",
      "train loss:1.5057917465530988\n",
      "train loss:1.3375143850791205\n",
      "train loss:1.4595532654080867\n",
      "=== epoch:243, train acc:0.6066666666666667, test acc:0.4763 ===\n",
      "train loss:1.3756074291593703\n",
      "train loss:1.5233943305340163\n",
      "train loss:1.4573865504282557\n",
      "=== epoch:244, train acc:0.6066666666666667, test acc:0.4789 ===\n",
      "train loss:1.4945210035896355\n",
      "train loss:1.5294912709633033\n",
      "train loss:1.5579896580360904\n",
      "=== epoch:245, train acc:0.6133333333333333, test acc:0.4829 ===\n",
      "train loss:1.3219944498989906\n",
      "train loss:1.4564962269052728\n",
      "train loss:1.4042153589770543\n",
      "=== epoch:246, train acc:0.6066666666666667, test acc:0.485 ===\n",
      "train loss:1.50987725694942\n",
      "train loss:1.3802065075684313\n",
      "train loss:1.3457199848223125\n",
      "=== epoch:247, train acc:0.6066666666666667, test acc:0.4868 ===\n",
      "train loss:1.5809617465535224\n",
      "train loss:1.4852192943449625\n",
      "train loss:1.4535386737253868\n",
      "=== epoch:248, train acc:0.6066666666666667, test acc:0.4905 ===\n",
      "train loss:1.2762396671659209\n",
      "train loss:1.6114986622475522\n",
      "train loss:1.2533054957630663\n",
      "=== epoch:249, train acc:0.6033333333333334, test acc:0.4874 ===\n",
      "train loss:1.539866678289676\n",
      "train loss:1.3940736653803907\n",
      "train loss:1.4767860224979368\n",
      "=== epoch:250, train acc:0.6066666666666667, test acc:0.4926 ===\n",
      "train loss:1.4367963512275106\n",
      "train loss:1.5670053234765309\n",
      "train loss:1.430754487050641\n",
      "=== epoch:251, train acc:0.6066666666666667, test acc:0.4954 ===\n",
      "train loss:1.5370042043086087\n",
      "train loss:1.3929995039993512\n",
      "train loss:1.3472887424753752\n",
      "=== epoch:252, train acc:0.6166666666666667, test acc:0.5007 ===\n",
      "train loss:1.4402418046950418\n",
      "train loss:1.3844506783452257\n",
      "train loss:1.5274860940718131\n",
      "=== epoch:253, train acc:0.62, test acc:0.5035 ===\n",
      "train loss:1.2754199899165284\n",
      "train loss:1.5211230853932844\n",
      "train loss:1.455023039474675\n",
      "=== epoch:254, train acc:0.63, test acc:0.5046 ===\n",
      "train loss:1.2707913528496457\n",
      "train loss:1.5084540043246433\n",
      "train loss:1.4229972678380705\n",
      "=== epoch:255, train acc:0.6366666666666667, test acc:0.5044 ===\n",
      "train loss:1.48725392076924\n",
      "train loss:1.3586546137396756\n",
      "train loss:1.48018820947487\n",
      "=== epoch:256, train acc:0.6366666666666667, test acc:0.5046 ===\n",
      "train loss:1.365141634860302\n",
      "train loss:1.350156382682239\n",
      "train loss:1.3456098136205576\n",
      "=== epoch:257, train acc:0.64, test acc:0.5065 ===\n",
      "train loss:1.2938364603061503\n",
      "train loss:1.4116404115037238\n",
      "train loss:1.2934422821326441\n",
      "=== epoch:258, train acc:0.6333333333333333, test acc:0.5051 ===\n",
      "train loss:1.374959454097645\n",
      "train loss:1.3630074855635959\n",
      "train loss:1.5878653420323234\n",
      "=== epoch:259, train acc:0.6466666666666666, test acc:0.5087 ===\n",
      "train loss:1.4799401726558243\n",
      "train loss:1.5149072807559318\n",
      "train loss:1.3473648798717843\n",
      "=== epoch:260, train acc:0.6433333333333333, test acc:0.5076 ===\n",
      "train loss:1.4231407170641543\n",
      "train loss:1.426779964568762\n",
      "train loss:1.4842339536136202\n",
      "=== epoch:261, train acc:0.6466666666666666, test acc:0.509 ===\n",
      "train loss:1.2366333977174138\n",
      "train loss:1.2566256553266086\n",
      "train loss:1.465549243946694\n",
      "=== epoch:262, train acc:0.64, test acc:0.5101 ===\n",
      "train loss:1.365325554154337\n",
      "train loss:1.3444307320856752\n",
      "train loss:1.2263942849800116\n",
      "=== epoch:263, train acc:0.65, test acc:0.5111 ===\n",
      "train loss:1.3424054884234926\n",
      "train loss:1.2828427271283394\n",
      "train loss:1.4216047310995603\n",
      "=== epoch:264, train acc:0.64, test acc:0.5098 ===\n",
      "train loss:1.29705815965703\n",
      "train loss:1.2991871895757887\n",
      "train loss:1.3759745974319162\n",
      "=== epoch:265, train acc:0.65, test acc:0.5136 ===\n",
      "train loss:1.2827850104100746\n",
      "train loss:1.2743172315335265\n",
      "train loss:1.4343450915104148\n",
      "=== epoch:266, train acc:0.6466666666666666, test acc:0.511 ===\n",
      "train loss:1.2828208588315655\n",
      "train loss:1.340476637489247\n",
      "train loss:1.3736893039845954\n",
      "=== epoch:267, train acc:0.64, test acc:0.5096 ===\n",
      "train loss:1.3205130907727993\n",
      "train loss:1.29079732476607\n",
      "train loss:1.1849582838113504\n",
      "=== epoch:268, train acc:0.64, test acc:0.5117 ===\n",
      "train loss:1.3247903590500538\n",
      "train loss:1.1800990386714993\n",
      "train loss:1.2466410881918875\n",
      "=== epoch:269, train acc:0.6433333333333333, test acc:0.5117 ===\n",
      "train loss:1.4103241860552158\n",
      "train loss:1.3084781037927735\n",
      "train loss:1.1391905080485651\n",
      "=== epoch:270, train acc:0.6533333333333333, test acc:0.5111 ===\n",
      "train loss:1.3543638854166253\n",
      "train loss:1.2678449766897613\n",
      "train loss:1.2451627185561351\n",
      "=== epoch:271, train acc:0.6466666666666666, test acc:0.5113 ===\n",
      "train loss:1.3504721883626345\n",
      "train loss:1.3767340432443635\n",
      "train loss:1.4000468511970874\n",
      "=== epoch:272, train acc:0.6466666666666666, test acc:0.5099 ===\n",
      "train loss:1.2726153398960982\n",
      "train loss:1.2263855183508567\n",
      "train loss:1.2689349701893302\n",
      "=== epoch:273, train acc:0.6533333333333333, test acc:0.5136 ===\n",
      "train loss:1.1840138744136772\n",
      "train loss:1.3235917633288445\n",
      "train loss:1.3385239587174835\n",
      "=== epoch:274, train acc:0.6533333333333333, test acc:0.5133 ===\n",
      "train loss:1.1842265582579465\n",
      "train loss:1.2531568277885845\n",
      "train loss:1.2516008725281695\n",
      "=== epoch:275, train acc:0.6533333333333333, test acc:0.5121 ===\n",
      "train loss:1.252877232915479\n",
      "train loss:1.234338465188414\n",
      "train loss:1.2713627240298286\n",
      "=== epoch:276, train acc:0.6566666666666666, test acc:0.5145 ===\n",
      "train loss:1.2963195582755611\n",
      "train loss:1.2742483838753997\n",
      "train loss:1.3288601052683062\n",
      "=== epoch:277, train acc:0.6633333333333333, test acc:0.519 ===\n",
      "train loss:1.1921193166609134\n",
      "train loss:1.2220872570942594\n",
      "train loss:1.4611451347811613\n",
      "=== epoch:278, train acc:0.6733333333333333, test acc:0.5225 ===\n",
      "train loss:1.2520428746284324\n",
      "train loss:1.251451818282117\n",
      "train loss:1.1693273530196002\n",
      "=== epoch:279, train acc:0.67, test acc:0.5211 ===\n",
      "train loss:1.387186849114517\n",
      "train loss:1.307313267013753\n",
      "train loss:1.2900859576708523\n",
      "=== epoch:280, train acc:0.67, test acc:0.5205 ===\n",
      "train loss:1.2690608628781583\n",
      "train loss:1.2405217496151948\n",
      "train loss:1.1515617822768787\n",
      "=== epoch:281, train acc:0.6733333333333333, test acc:0.5207 ===\n",
      "train loss:1.2596435070937633\n",
      "train loss:1.3085342726641451\n",
      "train loss:1.2947026778046729\n",
      "=== epoch:282, train acc:0.6666666666666666, test acc:0.5201 ===\n",
      "train loss:1.3146847389613212\n",
      "train loss:1.297380855108367\n",
      "train loss:1.2550738434150974\n",
      "=== epoch:283, train acc:0.66, test acc:0.518 ===\n",
      "train loss:1.105491869156235\n",
      "train loss:1.183480977712485\n",
      "train loss:1.221148210805517\n",
      "=== epoch:284, train acc:0.6633333333333333, test acc:0.5236 ===\n",
      "train loss:1.1729618147751233\n",
      "train loss:1.288012344885479\n",
      "train loss:1.141824673878527\n",
      "=== epoch:285, train acc:0.6633333333333333, test acc:0.5212 ===\n",
      "train loss:1.2700399407578475\n",
      "train loss:1.101289534024259\n",
      "train loss:1.1347689070171496\n",
      "=== epoch:286, train acc:0.67, test acc:0.5217 ===\n",
      "train loss:1.1317750708658707\n",
      "train loss:1.1955594327011376\n",
      "train loss:1.406037902560264\n",
      "=== epoch:287, train acc:0.66, test acc:0.5212 ===\n",
      "train loss:1.217772124811065\n",
      "train loss:1.109735611915247\n",
      "train loss:1.2153375390678618\n",
      "=== epoch:288, train acc:0.67, test acc:0.5269 ===\n",
      "train loss:1.244166922305047\n",
      "train loss:1.12471403180798\n",
      "train loss:1.0455980644763843\n",
      "=== epoch:289, train acc:0.6666666666666666, test acc:0.525 ===\n",
      "train loss:1.043291226252811\n",
      "train loss:1.063412329331486\n",
      "train loss:1.1293284196572537\n",
      "=== epoch:290, train acc:0.6633333333333333, test acc:0.5228 ===\n",
      "train loss:1.1964041193575976\n",
      "train loss:1.0716854088733887\n",
      "train loss:1.2924557007605215\n",
      "=== epoch:291, train acc:0.6633333333333333, test acc:0.5259 ===\n",
      "train loss:1.2085218895689926\n",
      "train loss:1.2130905287527882\n",
      "train loss:1.1941398680612558\n",
      "=== epoch:292, train acc:0.67, test acc:0.5282 ===\n",
      "train loss:1.0723232146565804\n",
      "train loss:1.0455175249292992\n",
      "train loss:1.1688063589693192\n",
      "=== epoch:293, train acc:0.67, test acc:0.5263 ===\n",
      "train loss:1.2041462861260788\n",
      "train loss:1.2205995782090402\n",
      "train loss:1.283537182011652\n",
      "=== epoch:294, train acc:0.6766666666666666, test acc:0.5329 ===\n",
      "train loss:1.0860658290010872\n",
      "train loss:1.2786740353582167\n",
      "train loss:1.2303867675203872\n",
      "=== epoch:295, train acc:0.68, test acc:0.5335 ===\n",
      "train loss:1.1627189573862784\n",
      "train loss:1.3018619058495255\n",
      "train loss:0.9795080524133957\n",
      "=== epoch:296, train acc:0.69, test acc:0.539 ===\n",
      "train loss:1.1324719129722096\n",
      "train loss:1.0955499383937342\n",
      "train loss:1.0827422863845257\n",
      "=== epoch:297, train acc:0.6833333333333333, test acc:0.535 ===\n",
      "train loss:1.12000197370828\n",
      "train loss:1.12264742661184\n",
      "train loss:0.9948481124665604\n",
      "=== epoch:298, train acc:0.69, test acc:0.5355 ===\n",
      "train loss:1.1306419065862519\n",
      "train loss:1.0511888864292476\n",
      "train loss:1.1283068657598518\n",
      "=== epoch:299, train acc:0.6866666666666666, test acc:0.5349 ===\n",
      "train loss:1.1000584699060385\n",
      "train loss:1.1430996605516783\n",
      "train loss:1.206677024825247\n",
      "=== epoch:300, train acc:0.6866666666666666, test acc:0.5373 ===\n",
      "train loss:1.2258385287618763\n",
      "train loss:1.1626341293192626\n",
      "train loss:0.9685724541243259\n",
      "=== epoch:301, train acc:0.6833333333333333, test acc:0.5371 ===\n",
      "train loss:1.0328804289625768\n",
      "train loss:1.1307775231342385\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.5387\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ch06/overfit_dropout.py\n",
    "# commom/trainer.py\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.pardir)  # 为了导入父目录的文件而进行的设定\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from common.multi_layer_net_extend import MultiLayerNetExtend\n",
    "from common.trainer import Trainer\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)\n",
    "\n",
    "# 为了再现过拟合，减少学习数据\n",
    "x_train = x_train[:300]\n",
    "t_train = t_train[:300]\n",
    "\n",
    "# 设定是否使用Dropuout，以及比例 ========================\n",
    "use_dropout = True  # 不使用Dropout的情况下为False\n",
    "dropout_ratio = 0.2\n",
    "# ====================================================\n",
    "\n",
    "network = MultiLayerNetExtend(input_size=784, hidden_size_list=[100, 100, 100, 100, 100, 100],\n",
    "                              output_size=10, use_dropout=use_dropout, dropout_ration=dropout_ratio)\n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=301, mini_batch_size=100,\n",
    "                  optimizer='sgd', optimizer_param={'lr': 0.01}, verbose=True)\n",
    "trainer.train()\n",
    "\n",
    "train_acc_list, test_acc_list = trainer.train_acc_list, trainer.test_acc_list\n",
    "\n",
    "# 绘制图形==========\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(len(train_acc_list))\n",
    "plt.plot(x, train_acc_list, marker='o', label='train', markevery=10)\n",
    "plt.plot(x, test_acc_list, marker='s', label='test', markevery=10)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7bebbcdb67a87c960e72e49b9762de1591139e5dbbdfaa6c9d42133d04bebfbc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
